# lightning.pytorch==2.5.1.post0
# Test configuration - minimal config that will be merged with training config from checkpoint
seed_everything: true

trainer:
  accelerator: gpu
  devices: 1
  num_nodes: 1
  precision: 16-mixed
  logger:
    - class_path: lightning.pytorch.loggers.TensorBoardLogger
      init_args:
        save_dir: ./saved/
        name: test_ew_xfmr

# Test-specific overrides - these will override training config
model:
  class_path: ml.modules.trace_ew_module.TraceEWModule
  init_args:
    ckpt_path: ./saved/ew_xfmr/version_23/checkpoints/last.ckpt 
    use_laplace_on_fit_end: false  # Disable Laplace for testing
    compile_model: false  # Disable compilation for testing

# Test data configuration
data:
  class_path: ml.data.eyewidth_data.TraceSeqEWDataloader
  init_args:
    data_dirs:
      5mi: /proj/siaiadm/ew_predictor/test_data/sub_task/trace_input/5mi
      8mi: /proj/siaiadm/ew_predictor/test_data/sub_task/trace_input/8mi
      9mi: /proj/siaiadm/ew_predictor/test_data/sub_task/trace_input/9mi
    label_dir: /proj/siaiadm/ew_predictor/data/sbr/test
    batch_size: 100