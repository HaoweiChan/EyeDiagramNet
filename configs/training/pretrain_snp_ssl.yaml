# lightning.pytorch
seed_everything: true

trainer:
  accelerator: gpu
  devices: -1
  precision: 16-mixed
  max_epochs: 1000
  gradient_clip_val: 1.0
  gradient_clip_algorithm: norm
  log_every_n_steps: 10
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: saved
      name: snp_ssl_improved
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: train_loss
        dirpath: saved/snp_ssl_improved/checkpoints
        filename: snp-encoder-epoch{epoch:02d}-train_loss{train_loss:.5f}
        auto_insert_metric_name: false
        save_last: true
        save_top_k: 5
        mode: min
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: ml.callbacks.visualization_callbacks.SParameterVisualizer
      init_args:
        num_samples: 2
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: train_loss
        patience: 50
        mode: min
        verbose: true
    - class_path: lightning.pytorch.callbacks.GradientAccumulationScheduler
      init_args:
        scheduling: {0: 1, 100: 2, 200: 4}

model:
  class_path: ml.modules.snp_ssl_module.SNPSelfSupervisedModule
  init_args:
    encoder:
      class_path: ml.models.snp_model.OptimizedSNPEmbedding
      init_args:
        model_dim: 768
        freq_length: 256
        use_checkpointing: false
        use_mixed_precision: true
        use_tx_rx_tokens: false
    decoder:
      class_path: ml.models.snp_model.AttentionSNPDecoder
      init_args:
        model_dim: 768
        freq_length: 256
        num_attention_layers: 2
        num_heads: 8
        mlp_hidden_ratio: 4
        dropout_rate: 0.1
        use_separate_phase_mag: true
        use_checkpointing: false
        use_mixed_precision: true
        enforce_symmetry: false
    loss_fn:
      class_path: ml.utils.snp_losses.ImprovedSNPReconstructionLoss
      init_args:
        magnitude_weight: 1.0
        phase_weight: 1.5
        complex_weight: 0.5
        spectral_weight: 0.3
        use_unwrapped_phase: true
        latent_reg_type: l2
        latent_reg_weight: 0.001
        gradient_penalty_weight: 0.1

data:
  class_path: ml.data.snp_dataloader.SNPDataModule
  init_args:
    data_dirs:
      - /proj/siaiadm/AI_training_data/D2D/vertical/snp_for_UCIE_20250121
      - /proj/siaiadm/AI_training_data/D2D/from_enzo
    file_pattern: "*.S96P"
    batch_size: 32
    num_workers: 4
    pin_memory: true
    cache_in_memory: true
    augmentation_config:
      rotation_prob: 0.5
      reflection_prob: 0.5
      port_permutation_prob: 0.3
      freq_mask_prob: 0.2
      freq_mask_ratio: 0.15
      noise_prob: 0.1
      noise_std: 0.01

optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 1e-4
    betas: [0.9, 0.999]
    weight_decay: 0.01
    eps: 1e-8

lr_scheduler:
  class_path: ml.utils.lr_schedulers.CosineAnnealingWarmRestartsWithWarmupDecay
  init_args:
    T_0: 20
    T_mult: 2
    eta_min: 0.
    warmup_epochs: 10
    decay_factor: 0.5

# Optional: Override for testing with smaller dataset
# ckpt_path: null  # Path to resume from checkpoint 