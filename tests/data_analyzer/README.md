# Eye Diagram Data Analyzer

This directory contains a comprehensive tool for analyzing, cleaning, and validating the pickle files generated by the data collector.

## Main Script

The primary entry point for this tool is `tests/analyze_pickle_data.py`.

## Usage

The tool is structured with subcommands to perform different tasks. The basic structure of a command is:

```bash
python tests/analyze_pickle_data.py <path_to_pickle_dir> <command> [options]
```

### Commands

There are three main commands available: `analyze`, `clean`, and `validate`.

---

### 1. `analyze`

This command performs a full analysis of the data in the specified directory. It provides summary statistics, generates distribution plots, and creates a detailed report.

**Usage:**
```bash
python tests/analyze_pickle_data.py /path/to/your/pickle_data analyze
```

**What it does:**
-   Loads all pickle files and aggregates the data.
-   Calculates statistics for eye-widths, direction block sizes, and file sample counts.
-   Generates and saves plots for eye-width distributions (`eye_width_distributions.png`).
-   Generates and saves a detailed text summary (`training_data_summary.txt`).
-   All outputs are saved to a timestamped directory inside `tests/`, for example `tests/analyzer_output_20231027_123456/`.

---

### 2. `clean`

This command performs in-place cleaning of the pickle files. It can remove samples based on several criteria. A backup of each modified file is created with a `.bak` extension.

**Usage:**
```bash
python tests/analyze_pickle_data.py /path/to/your/pickle_data clean [options]
```

**Options:**

-   `--block_size <N>`:
    -   Only keeps samples where the estimated direction block size is exactly `<N>`.
    -   **Example:** To keep only samples with a block size of 2:
        ```bash
        python tests/analyze_pickle_data.py ./data clean --block_size 2
        ```

-   `--remove-block-size-1`:
    -   Removes samples that are known to be "contaminated" from older collection processes, which are identified by having a direction block size of 1.
    -   **Example:**
        ```bash
        python tests/analyze_pickle_data.py ./data clean --remove-block-size-1
        ```

You can combine these options. For example, to only keep samples with block size 2 and also remove any block size 1 patterns (though this is somewhat redundant):
```bash
python tests/analyze_pickle_data.py ./data clean --block_size 2 --remove-block-size-1
```

---

### 3. `validate`

This command validates the eye-width data in the pickle files by re-running the simulation for a subset of samples and comparing the results. This is useful for verifying data integrity and the consistency of the simulation engine.

**Usage:**
```bash
python tests/analyze_pickle_data.py /path/to/your/pickle_data validate [options]
```

**Options:**

-   `--max_files <N>`:
    -   The maximum number of randomly selected pickle files to validate. Defaults to `3`.
    -   **Example:** To validate 10 files:
        ```bash
        python tests/analyze_pickle_data.py ./data validate --max_files 10
        ```

-   `--max_samples <M>`:
    -   The maximum number of samples to validate from *each* selected file. Defaults to `5`.
    -   **Example:** To validate 20 samples from each file:
        ```bash
        python tests/analyze_pickle_data.py ./data validate --max_samples 20
        ```

**What it does:**
-   Randomly selects files and samples to validate.
-   For each sample, it reconstructs the configuration and re-runs the simulation.
-   It calculates the difference and relative error between the stored eye-width and the newly simulated one.
-   Generates a detailed CSV report (`validation_comparison_details.csv`) and plots comparing the results.
-   All outputs are saved to a timestamped directory inside `tests/`.
